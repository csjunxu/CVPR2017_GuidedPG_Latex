\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Rebuttal for Paper ID 1047}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}


%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW

We appreciate all the reviewers for their constructive comments, especially R2 for your encouraging comments.
\\
\textbf{R1's Questions}
\\
\textbf{Q1}: Overstatement of claims
\\
The noise in real world images are very complex and cannot be modeled by Poisson or other more complex distribution. Since it is too hard to explicitly model the real noise, we gave up designing good models for real noise. Instead, we turn to model the signals by statistical models such as mixture of Gaussian (MoG). We believe that as long as we model the signals accurately enough, we do not need strong priors for the noise, and hence we employ the $\ell_{2}$ norm for the residual errors. We admit that if we describe the noise with a more suitable model, the performance of our algorithm will be better. But this is not the major point of this paper, as pointed out by the title of this paper.
\\
\textbf{Q2}: There is nothing new in terms of the prior model ...
\\
When taking the MoG model for learning priors from external data, we basically follow the framework of EPLL. However, this is not the exact work we have done in this paper. What we did is to employ the external priors learned from external data to guide the learning of internal priors which are more adaptive to the image being denoised. And we want to argue that this combination makes our model have stronger ability to characterize the signals in real noisy images. The results of two Poisson algorithm are listed in Table 1. 
\begin{table}\vspace{1.5mm}
\caption{Average PSNR(dB) results of different methods on 60 real noisy images cropped from \cite{crosschannel2016}.}
\vspace{-3mm}
\label{tab3}
\begin{center}
\renewcommand\arraystretch{1}
\begin{tabular}{|c||c|c|c|c|}
\hline
 Methods& \textbf{CBM3D}&\textbf{WNNM}&\textbf{MLP}&\textbf{CSF}
\\
\hline
PSNR &   34.58 & 34.52 & 36.19 & 37.40
\\
\hline
Methods& \textbf{TNRD} & \textbf{NI} & \textbf{NC} &\textbf{Ours} 
\\
\hline
PSNR & 37.75  & 36.53 & 37.57 & {\textbf{{ 38.75}}}
\\
\hline
\end{tabular}
\end{center}\vspace{-2.5mm}
\end{table}
\\
\textbf{R2's Questions}
\\
\textbf{Q1}: The number and effect of parameters
\\
The key parameters of our model are the regularization parameter $\lambda$ and the number of atoms in external sub-dictionary,$r$. $r$ is very robust as long as it is in a reasonable range as demonstrated in experiments. $\lambda=0.001$ works well in the experiments. Other parameters are preset by hand and can work well as long as they are set in a reasonable range.
\\
\textbf{R3's Questions}
\\
\textbf{Q1}: hard to believe that it will work for all the cases
\\
We had tested our method on the two datasets which contains a lot of real noisy images for many cases, we will test our method and publish our code in the future for testing on more cases.
\\
\textbf{Q2}: not clear how to choose nonlocal similar patches
\\
Yes, we chose similar patches based on Euclidean distance and we added this detail to our revised paper. Thanks for pointing out.
\\
\textbf{Q3}: other noise types
\\
In this paper, we only deal with real noise in real noisy images.
\\
\textbf{Q4}: the likelihood term is Gaussian denoising
\\
Please kindly refer to the answers to \textbf{Q1} of \textbf{R1} and \textbf{Q3} above for this problem since the space is limited. 
\\
\textbf{Q5}: The competing algorithms would also work quite well
\\
We retained the TNRD, CSF or MLP model with the parameters set as the best performance cases as described in their corresponding paper, with Gaussian noise levels $\sigma = 5, 10, 15, 25, 35, 50, and 75$. We found that the best average PSNR results on the 15 and 60 images used in our paper happens with TNRD at $\sigma = 10$, which are 36.61dB and 38.32dB, respectively, 1.0dB and 0.57dB higher than the results with default parameter settings. But these results are still 0.55dB and 0.43dB, respectively, lower than the results of our method. The image qualities of TNRD at $\sigma = 10$ are still clearly inferior to those of our method. The whole retrained results are listed in Table 1.
\\
\textbf{Q6}: a single parameter setting for all the cases 
\\
The experiments demonstrate that a single parameter can deal with all the cases in the tested datasets. With more flexible parameters setting, the performance would be better and this is the line of our future work.
\\
\textbf{Q7}: why is the image resolution significantly smaller
\\
This is for smaller pdf size of the paper, and down scale the images would not affect much the image quality.



{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
